global:
  benchmark_name: MNIST
  output_dir: src/Python/Benchmarks/MNIST/models

  logging:
    info_freq: 100
    local_log_path: src/Python/Benchmarks/MNIST/experiments.log
    wandb:
      entity: m24842
      project: Machine Learning
      metrics: [acc, loss]
  
  dataset:
    name: SequentialMNIST
    splits:
      train:
        root: data
        train: True
        permuted: False
      test:
        root: data
        train: False
        permuted: False
  
  checkpoint_freq: 500

experiments:
  - general:
      model_name: CompressionTransformer
      load_checkpoint: False
      seed: 0
      batch_size: 64
      epochs: 10
      grad_clip_norm: 1.0
    
    model:
      emb_dim: 128
      mlp_dim: 128
      mem_dim: 16
      n_heads: 4
      n_layers: 2
      input_dim: 1
      output_dim: 10
      dropout: 0.1
      causal: False
      use_embedding: False
    
    optimizer:
      name: AdamW
      lr: 1e-3
      weight_decay: 0.01
    
    scheduler:
      name: CosineAnnealingLR
      T_max: 10
      eta_min: 1e-6