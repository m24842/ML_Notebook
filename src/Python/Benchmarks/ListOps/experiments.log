05-04-2025 23:32 - CompressionTransformer
Total params: 410,256
Hyperparams:
	emb_dim: 128
	mlp_dim: 128
	mem_dim: 16
	n_heads: 4
	n_layers: 4
	input_dim: 17
	output_dim: 10
	dropout: 0.1
	causal: False
	use_embedding: True
	benchmark: ListOps
	model: CompressionTransformer
	seed: 3333
	warmup_epochs: 0
	total_epochs: 10
	bsz: 32
	lr: 0.0003
	weight_decay: 0.01
	permuted: None
Train accuracies:
	23.48, 35.56, 36.05, 36.15, 36.70, 37.14, 37.57, 37.92, 38.12, 38.40
Test accuracies:
	33.30, 33.35, 32.90, 30.35, 30.00, 29.45, 29.00, 27.50, 28.30, 28.55
05-05-2025 05:21 - Transformer
Total params: 402,064
Hyperparams:
	emb_dim: 128
	mlp_dim: 128
	n_heads: 4
	n_layers: 4
	input_dim: 17
	output_dim: 10
	dropout: 0.1
	causal: False
	use_embedding: True
	benchmark: ListOps
	model: Transformer
	seed: 0
	warmup_epochs: 0
	total_epochs: 10
	bsz: 32
	lr: 0.0003
	weight_decay: 0.01
	permuted: None
Train accuracies:
	33.63, 36.38, 37.17, 37.87, 38.30, 38.51, 38.97, 39.24, 39.50, 39.56
Test accuracies:
	20.45, 19.00, 22.80, 24.05, 19.90, 20.15, 17.75, 14.85, 12.70, 12.10
05-05-2025 11:19 - Transformer
Total params: 402,064
Hyperparams:
	emb_dim: 128
	mlp_dim: 128
	n_heads: 4
	n_layers: 4
	input_dim: 17
	output_dim: 10
	dropout: 0.1
	causal: False
	use_embedding: True
	benchmark: ListOps
	model: Transformer
	seed: 42
	warmup_epochs: 0
	total_epochs: 10
	bsz: 32
	lr: 0.0003
	weight_decay: 0.01
	permuted: None
Train accuracies:
	32.67, 36.11, 37.05, 37.78, 38.46, 38.75, 39.20, 39.59, 39.72, 39.88
Test accuracies:
	32.45, 20.75, 20.85, 18.55, 20.95, 20.40, 20.55, 18.15, 18.55, 18.40
05-05-2025 17:29 - Transformer
Total params: 402,064
Hyperparams:
	emb_dim: 128
	mlp_dim: 128
	n_heads: 4
	n_layers: 4
	input_dim: 17
	output_dim: 10
	dropout: 0.1
	causal: False
	use_embedding: True
	benchmark: ListOps
	model: Transformer
	seed: 1111
	warmup_epochs: 0
	total_epochs: 10
	bsz: 32
	lr: 0.0003
	weight_decay: 0.01
	permuted: None
Train accuracies:
	30.48, 36.15, 37.10, 37.85, 38.33, 38.90, 39.09, 39.36, 39.67, 39.90
Test accuracies:
	29.20, 28.90, 30.80, 33.05, 34.70, 34.35, 34.65, 34.50, 34.75, 34.25
